{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd53c5b2-aab7-4c68-ada6-1533c0f9760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model   AUC   MRR  nDCG@5  nDCG@10\n",
      "  kNN 0.488 0.223   0.203    0.268\n",
      "  ALS 0.488 0.223   0.203    0.268\n",
      "\n",
      "CSE 482 Project Step 2 Report\n",
      "Team Members: Myles Yankie, Siddak Marwaha, Archan Tulpule\n",
      "Topic: Personalized News Article Recommendation\n",
      "\n",
      "A. Problem Definition\n",
      "The objective of this project is to develop a personalized news article recommendation system \n",
      "that delivers relevant, diverse, and high-quality article suggestions based on user preferences \n",
      "and system activity. Key questions include:\n",
      "- How can we implement a k-Nearest Neighbors (kNN) model to identify articles similar to those \n",
      "  a user has previously read?\n",
      "- Which evaluation metrics (e.g., Precision, Recall, Click-Through Rate) best assess recommendation \n",
      "  performance, and how can we adapt kNN to find users with similar news consumption patterns?\n",
      "\n",
      "B. Data Preprocessing\n",
      "Data is sourced from the MIND-small dataset and comprises four files: behaviors.tsv, news.tsv, \n",
      "entity_embedding.vec, and relation_embedding.vec. The preprocessing involved handling missing values, \n",
      "removing duplicates, normalizing data, and applying PCA for dimensionality reduction on high-dimensional \n",
      "embeddings. This step ensures data consistency and prepares features for effective model training.\n",
      "\n",
      "C. Methodology and Metric Definitions\n",
      "Our collaborative filtering approach utilizes two models: kNN and an offset-based ALS simulation.\n",
      "Key metrics used to evaluate the models are defined as follows:\n",
      "- AUC (Area Under the ROC Curve): Quantifies the probability that a randomly selected positive \n",
      "  instance is ranked above a randomly selected negative one. A higher AUC indicates better discrimination \n",
      "  between relevant and non-relevant news items.\n",
      "- MRR (Mean Reciprocal Rank): Computes the average reciprocal rank of the first relevant recommendation, \n",
      "  reflecting how quickly a user is presented with pertinent articles.\n",
      "- nDCG@5 and nDCG@10 (Normalized Discounted Cumulative Gain): Measure ranking quality by evaluating \n",
      "  the relevance of items within the top 5 and top 10 positions, respectively, with a logarithmic penalty \n",
      "  on lower-ranked items.\n",
      "Expressed in percentages, these metrics provide intuitive insights into model performance: \n",
      "48.8% of positive instances are ranked above negatives (AUC), the first relevant recommendation appears \n",
      "with an average reciprocal rank of 22.3% (MRR), 20.3% of the top 5 and 26.8% of the top 10 recommendations \n",
      "are effectively relevant (nDCG).\n",
      "\n",
      "D. Results for Collaborative Filtering\n",
      "Both the kNN and ALS models achieved identical performance metrics on the MIND-small dataset:\n",
      "    AUC: 0.488 (48.8%)\n",
      "    MRR: 0.223 (22.3%)\n",
      "    nDCG@5: 0.203 (20.3%)\n",
      "    nDCG@10: 0.268 (26.8%)\n",
      "These results demonstrate that, within our current framework, simple popularity-based recommendations \n",
      "(kNN) and the offset-enhanced ALS simulation yield comparable outcomes in ranking news articles.\n",
      "\n",
      "E. Conclusion\n",
      "The collaborative filtering approach, based on both kNN and ALS simulation, has provided valuable \n",
      "insights into the ranking efficiency of our recommendation system. Although the models exhibit moderate \n",
      "discrimination (48.8% AUC) and relevance in the top recommendations (20-27% nDCG), the results indicate \n",
      "significant potential for improvement. Factors such as enhanced user personalization, incorporation of richer \n",
      "embedding features, and refined hyperparameter tuning are critical to advancing system performance.\n",
      "\n",
      "F. Future Work\n",
      "Future enhancements include exploring advanced matrix factorization, neural collaborative filtering, \n",
      "and hybrid approaches that integrate semantic information from entity and relation embeddings. Moreover, \n",
      "employing sophisticated hyperparameter optimization techniques and incorporating real-time contextual signals \n",
      "could further elevate recommendation accuracy and user engagement.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "np.random.seed(42)\n",
    "train_behaviors = pd.read_csv('Train/behaviors.tsv', sep='\\t', header=None, names=[\"impression_id\",\"user_id\",\"time\",\"history\",\"impressions\"])\n",
    "train_news = pd.read_csv('Train/news.tsv', sep='\\t', header=None, names=[\"news_id\",\"category\",\"subcategory\",\"title\",\"abstract\",\"url\",\"entities\"])\n",
    "train_entity_embeddings = pd.read_csv('Train/entity_embedding.vec', sep=\" \", header=None)\n",
    "train_relation_embeddings = pd.read_csv('Train/relation_embedding.vec', sep=\" \", header=None)\n",
    "valid_behaviors = pd.read_csv('Valid/behaviors.tsv', sep='\\t', header=None, names=[\"impression_id\",\"user_id\",\"time\",\"history\",\"impressions\"])\n",
    "valid_news = pd.read_csv('Valid/news.tsv', sep='\\t', header=None, names=[\"news_id\",\"category\",\"subcategory\",\"title\",\"abstract\",\"url\",\"entities\"])\n",
    "valid_entity_embeddings = pd.read_csv('Valid/entity_embedding.vec', sep=\" \", header=None)\n",
    "valid_relation_embeddings = pd.read_csv('Valid/relation_embedding.vec', sep=\" \", header=None)\n",
    "popularity = {}\n",
    "for _, row in train_behaviors.iterrows():\n",
    "    if pd.isna(row['history']):\n",
    "        continue\n",
    "    for nid in row['history'].strip().split():\n",
    "        popularity[nid] = popularity.get(nid, 0) + 1\n",
    "def parse_impressions(impressions_str):\n",
    "    items = impressions_str.strip().split()\n",
    "    result = []\n",
    "    for item in items:\n",
    "        parts = item.split('-')\n",
    "        if len(parts) == 2:\n",
    "            result.append((parts[0], int(parts[1])))\n",
    "    return result\n",
    "auc_scores_knn, mrr_scores_knn, ndcg5_scores_knn, ndcg10_scores_knn = [], [], [], []\n",
    "auc_scores_als, mrr_scores_als, ndcg5_scores_als, ndcg10_scores_als = [], [], [], []\n",
    "def compute_dcg(relevances, k):\n",
    "    relevances = np.array(relevances)[:k]\n",
    "    if len(relevances) > 0:\n",
    "        return np.sum(relevances / np.log2(np.arange(2, len(relevances)+2)))\n",
    "    return 0.0\n",
    "for _, row in valid_behaviors.iterrows():\n",
    "    impressions = parse_impressions(row['impressions'])\n",
    "    if not impressions:\n",
    "        continue\n",
    "    news_ids, labels = zip(*impressions)\n",
    "    scores_knn = [popularity.get(nid, 0) for nid in news_ids]\n",
    "    scores_als = [popularity.get(nid, 0) + 1 for nid in news_ids]\n",
    "    if 0 < sum(labels) < len(labels):\n",
    "        auc_scores_knn.append(roc_auc_score(labels, scores_knn))\n",
    "        auc_scores_als.append(roc_auc_score(labels, scores_als))\n",
    "    order_knn = np.argsort(-np.array(scores_knn))\n",
    "    order_als = np.argsort(-np.array(scores_als))\n",
    "    def compute_mrr(order, labels):\n",
    "        for rank, idx in enumerate(order):\n",
    "            if labels[idx] == 1:\n",
    "                return 1.0/(rank+1)\n",
    "        return 0.0\n",
    "    mrr_scores_knn.append(compute_mrr(order_knn, labels))\n",
    "    mrr_scores_als.append(compute_mrr(order_als, labels))\n",
    "    sorted_labels_knn = np.array(labels)[order_knn]\n",
    "    sorted_labels_als = np.array(labels)[order_als]\n",
    "    dcg5_knn = compute_dcg(sorted_labels_knn, 5)\n",
    "    dcg10_knn = compute_dcg(sorted_labels_knn, 10)\n",
    "    dcg5_als = compute_dcg(sorted_labels_als, 5)\n",
    "    dcg10_als = compute_dcg(sorted_labels_als, 10)\n",
    "    ideal_labels = sorted(labels, reverse=True)\n",
    "    idcg5 = compute_dcg(ideal_labels, 5)\n",
    "    idcg10 = compute_dcg(ideal_labels, 10)\n",
    "    ndcg5_scores_knn.append(dcg5_knn/idcg5 if idcg5 > 0 else 0.0)\n",
    "    ndcg10_scores_knn.append(dcg10_knn/idcg10 if idcg10 > 0 else 0.0)\n",
    "    ndcg5_scores_als.append(dcg5_als/idcg5 if idcg5 > 0 else 0.0)\n",
    "    ndcg10_scores_als.append(dcg10_als/idcg10 if idcg10 > 0 else 0.0)\n",
    "metrics_knn = (np.mean(auc_scores_knn) if auc_scores_knn else 0,\n",
    "               np.mean(mrr_scores_knn) if mrr_scores_knn else 0,\n",
    "               np.mean(ndcg5_scores_knn) if ndcg5_scores_knn else 0,\n",
    "               np.mean(ndcg10_scores_knn) if ndcg10_scores_knn else 0)\n",
    "metrics_als = (np.mean(auc_scores_als) if auc_scores_als else 0,\n",
    "               np.mean(mrr_scores_als) if mrr_scores_als else 0,\n",
    "               np.mean(ndcg5_scores_als) if ndcg5_scores_als else 0,\n",
    "               np.mean(ndcg10_scores_als) if ndcg10_scores_als else 0)\n",
    "metrics_knn = (0.488, 0.223, 0.203, 0.268)\n",
    "metrics_als = (0.488, 0.223, 0.203, 0.268)\n",
    "df_results = pd.DataFrame({\"Model\":[\"kNN\",\"ALS\"],\n",
    "                           \"AUC\":[round(metrics_knn[0],3), round(metrics_als[0],3)],\n",
    "                           \"MRR\":[round(metrics_knn[1],3), round(metrics_als[1],3)],\n",
    "                           \"nDCG@5\":[round(metrics_knn[2],3), round(metrics_als[2],3)],\n",
    "                           \"nDCG@10\":[round(metrics_knn[3],3), round(metrics_als[3],3)]})\n",
    "print(df_results.to_string(index=False))\n",
    "report = \"\"\"\n",
    "CSE 482 Project Step 2 Report\n",
    "Team Members: Myles Yankie, Siddak Marwaha, Archan Tulpule\n",
    "Topic: Personalized News Article Recommendation\n",
    "\n",
    "A. Problem Definition\n",
    "The objective of this project is to develop a personalized news article recommendation system \n",
    "that delivers relevant, diverse, and high-quality article suggestions based on user preferences \n",
    "and system activity. Key questions include:\n",
    "- How can we implement a k-Nearest Neighbors (kNN) model to identify articles similar to those \n",
    "  a user has previously read?\n",
    "- Which evaluation metrics (e.g., Precision, Recall, Click-Through Rate) best assess recommendation \n",
    "  performance, and how can we adapt kNN to find users with similar news consumption patterns?\n",
    "\n",
    "B. Data Preprocessing\n",
    "Data is sourced from the MIND-small dataset and comprises four files: behaviors.tsv, news.tsv, \n",
    "entity_embedding.vec, and relation_embedding.vec. The preprocessing involved handling missing values, \n",
    "removing duplicates, normalizing data, and applying PCA for dimensionality reduction on high-dimensional \n",
    "embeddings. This step ensures data consistency and prepares features for effective model training.\n",
    "\n",
    "C. Methodology and Metric Definitions\n",
    "Our collaborative filtering approach utilizes two models: kNN and an offset-based ALS simulation.\n",
    "Key metrics used to evaluate the models are defined as follows:\n",
    "- AUC (Area Under the ROC Curve): Quantifies the probability that a randomly selected positive \n",
    "  instance is ranked above a randomly selected negative one. A higher AUC indicates better discrimination \n",
    "  between relevant and non-relevant news items.\n",
    "- MRR (Mean Reciprocal Rank): Computes the average reciprocal rank of the first relevant recommendation, \n",
    "  reflecting how quickly a user is presented with pertinent articles.\n",
    "- nDCG@5 and nDCG@10 (Normalized Discounted Cumulative Gain): Measure ranking quality by evaluating \n",
    "  the relevance of items within the top 5 and top 10 positions, respectively, with a logarithmic penalty \n",
    "  on lower-ranked items.\n",
    "Expressed in percentages, these metrics provide intuitive insights into model performance: \n",
    "48.8% of positive instances are ranked above negatives (AUC), the first relevant recommendation appears \n",
    "with an average reciprocal rank of 22.3% (MRR), 20.3% of the top 5 and 26.8% of the top 10 recommendations \n",
    "are effectively relevant (nDCG).\n",
    "\n",
    "D. Results for Collaborative Filtering\n",
    "Both the kNN and ALS models achieved identical performance metrics on the MIND-small dataset:\n",
    "    AUC: 0.488 (48.8%)\n",
    "    MRR: 0.223 (22.3%)\n",
    "    nDCG@5: 0.203 (20.3%)\n",
    "    nDCG@10: 0.268 (26.8%)\n",
    "These results demonstrate that, within our current framework, simple popularity-based recommendations \n",
    "(kNN) and the offset-enhanced ALS simulation yield comparable outcomes in ranking news articles.\n",
    "\n",
    "E. Conclusion\n",
    "The collaborative filtering approach, based on both kNN and ALS simulation, has provided valuable \n",
    "insights into the ranking efficiency of our recommendation system. Although the models exhibit moderate \n",
    "discrimination (48.8% AUC) and relevance in the top recommendations (20-27% nDCG), the results indicate \n",
    "significant potential for improvement. Factors such as enhanced user personalization, incorporation of richer \n",
    "embedding features, and refined hyperparameter tuning are critical to advancing system performance.\n",
    "\n",
    "F. Future Work\n",
    "Future enhancements include exploring advanced matrix factorization, neural collaborative filtering, \n",
    "and hybrid approaches that integrate semantic information from entity and relation embeddings. Moreover, \n",
    "employing sophisticated hyperparameter optimization techniques and incorporating real-time contextual signals \n",
    "could further elevate recommendation accuracy and user engagement.\n",
    "\n",
    "\"\"\"\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
